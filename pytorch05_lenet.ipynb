{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积神经网络LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding=utf-8\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from torchvision.datasets import mnist # 导入 pytorch 内置的 mnist 数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1-使用MNIST数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We transform them to Tensors of normalized range [-1, 1]\n",
    "transform=transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                             ])\n",
    "\n",
    "train_set = mnist.MNIST('../../../dataset', train=True, transform=transform, download=False) \n",
    "test_set = mnist.MNIST('../../../dataset', train=False, transform=transform, download=False)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "# 使用 pytorch 自带的 DataLoader 定义一个数据迭代器\n",
    "trainloader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "testloader = DataLoader(test_set, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2-定义卷积网络LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5, padding=2) \n",
    "        self.pool  = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1   = nn.Linear(16*5*5, 120)\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16*5*5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3-训练网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 0.465\n",
      "[1,   200] loss: 0.415\n",
      "[1,   300] loss: 0.364\n",
      "[1,   400] loss: 0.320\n",
      "[1,   500] loss: 0.318\n",
      "[1,   600] loss: 0.273\n",
      "[1,   700] loss: 0.247\n",
      "[1,   800] loss: 0.242\n",
      "[1,   900] loss: 0.223\n",
      "[2,   100] loss: 0.208\n",
      "[2,   200] loss: 0.194\n",
      "[2,   300] loss: 0.179\n",
      "[2,   400] loss: 0.181\n",
      "[2,   500] loss: 0.169\n",
      "[2,   600] loss: 0.141\n",
      "[2,   700] loss: 0.144\n",
      "[2,   800] loss: 0.139\n",
      "[2,   900] loss: 0.150\n",
      "[3,   100] loss: 0.125\n",
      "[3,   200] loss: 0.134\n",
      "[3,   300] loss: 0.112\n",
      "[3,   400] loss: 0.125\n",
      "[3,   500] loss: 0.121\n",
      "[3,   600] loss: 0.116\n",
      "[3,   700] loss: 0.115\n",
      "[3,   800] loss: 0.110\n",
      "[3,   900] loss: 0.113\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss() #叉熵损失函数\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)  #使用SGD（随机梯度下降）优化，学习率为0.001，动量为0.9\n",
    "\n",
    "for epoch in range(3): # 遍历数据集\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    #enumerate(sequence, [start=0])，i序号，data是数据\n",
    "    for i, data in enumerate(trainloader, 0): \n",
    "        # get the inputs\n",
    "        inputs, labels = data   #data的结构是：[4x3x32x32的张量,长度4的张量]\n",
    "        \n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)  #把input数据从tensor转为variable\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad() #将参数的grad值初始化为0\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels) #将output和labels使用叉熵计算损失\n",
    "        loss.backward() #反向传播\n",
    "        optimizer.step() #用SGD更新参数\n",
    "        \n",
    "        # 每100批数据打印一次平均loss值\n",
    "        running_loss += loss.data[0]  #loss本身为Variable类型，所以要使用data获取其Tensor，因为其为标量，所以取0\n",
    "        if i % 100 == 99: # 每100批打印一次\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch+1, i+1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试集正确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 86 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    #print outputs.data\n",
    "    _, predicted = torch.max(outputs.data, 1)  #outputs.data是一个4x10张量，将每一行的最大的那一列的值和序号各自组成一个一维张量返回，第一个是值的张量，第二个是序号的张量。\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()   #两个一维张量逐行对比，相同的行记为1，不同的行记为0，再利用sum(),求总和，得到相同的个数。\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
